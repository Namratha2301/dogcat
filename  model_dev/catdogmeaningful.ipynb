{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Essential Modules and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob\n",
    "import librosa.display\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(\"drive/MyDrive/ProjectMGN/CatandDog/cats_dogs/train/cat\")\n",
    "cat_files = pd.DataFrame(filelist)\n",
    "metadata = pd.read_csv(\"drive/MyDrive/ProjectMGN/CatandDog/train_test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = os.listdir(\"drive/MyDrive/ProjectMGN/CatandDog/cats_dogs/train/dog\")\n",
    "dog_files = pd.DataFrame(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the Cat Dog Dataset and Shuffling the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_files['label']='0'\n",
    "dog_files['label']='1'\n",
    "df = pd.concat([dog_files,cat_files],ignore_index=True)\n",
    "df = df.rename(columns={0:'file'})\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Class Balance\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Erroneous Folders\n",
    "\n",
    "df[df['file']=='.DS_Store']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Extract Primary Features from Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "  # file_name - Directory to cat/dog audio files\n",
    "  try:\n",
    "    file_name = 'drive/MyDrive/ProjectMGN/CatandDog/cats_dogs/train/cat/'+str(data.file)\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "  except FileNotFoundError:\n",
    "    file_name = 'drive/MyDrive/ProjectMGN/CatandDog/cats_dogs/train/dog/'+str(data.file)\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "  # print(file_name)\n",
    "  mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=40).T,axis=0)\n",
    "  stft = np.abs(librosa.stft(X))\n",
    "  chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "  contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "  tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "  label = data.label\n",
    "  return mfccs, chroma, mel, contrast, tonnetz, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime=datetime.now()\n",
    "features_labels = df.apply(extract_features, axis=1)\n",
    "endtime=datetime.now()\n",
    "print(\"Total Time Taken:\",endtime-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Feature Labels\n",
    "\n",
    "features_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"len(feautures_labels):{len(features_labels)} and len(features_labels[0]):{len(features_labels[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Feature Vector Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('drive/MyDrive/ProjectMGN/features_label_catdog_max_dataset',features_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_labels=np.load('drive/MyDrive/ProjectMGN/features_label_catdog_max_dataset.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs for ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[]\n",
    "for i in range(0, len(features_labels)):\n",
    "    features.append(np.concatenate((features_labels[i][0], features_labels[i][1], \n",
    "                features_labels[i][2], features_labels[i][3],\n",
    "                features_labels[i][4]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"len(feautures):{len(features)} and len(features[0]):{len(features[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(features)\n",
    "y = np.array(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding Labels\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y = to_categorical(lb.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "TEST_LIMIT = 250\n",
    "x_train = X[:TEST_LIMIT]\n",
    "y_train = y[:TEST_LIMIT]\n",
    "x_test = X[TEST_LIMIT:]\n",
    "y_test = y[TEST_LIMIT:]\n",
    "X_train=ss.fit_transform(x_train)\n",
    "X_test=ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making and evaluating the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple dense model with early stopping with softmax for categorical classification\n",
    "# Total of 2 Classes - 0 representing Cat and representing  Dog\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(193, input_shape=(193,), activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics='accuracy')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Set figure size.\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate line plot of training, testing loss over epochs.\n",
    "plt.plot(train_accuracy, label='Training Accuracy', color='#185fad')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy', color='orange')\n",
    "\n",
    "# Set title\n",
    "plt.title('Training and Validation Accuracy by Epoch', fontsize = 25)\n",
    "plt.xlabel('Epoch', fontsize = 18)\n",
    "plt.ylabel('Categorical Crossentropy', fontsize = 18)\n",
    "plt.xticks(range(0,100,5), range(0,100,5))\n",
    "plt.legend(fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting On Test Data\n",
    "\n",
    "predict_x=model.predict(X_test) \n",
    "preds=np.argmax(predict_x,axis=1)\n",
    "preds = lb.inverse_transform(preds)\n",
    "df_test = df[TEST_LIMIT:]\n",
    "df_test['preds']=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test['label'] != df_test['preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test['label'] != df_test['preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking our model accuracy\n",
    "1-round(len(df_test[df_test['label'] != df_test['preds']])/len(df_test),3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('drive/MyDrive/Voice Detection/Saved Models/catdogmodel4error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_model = tf.keras.models.load_model('drive/MyDrive/Voice Detection/Saved Models/catdogmodelmaxdb')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get our predictions from the test data\n",
    "predict_x=new_model.predict(X_test) \n",
    "preds=np.argmax(predict_x,axis=1)\n",
    "preds = lb.inverse_transform(preds)\n",
    "df_test = df[TEST_LIMIT:]\n",
    "df_test['preds']=preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Predict Function for WebApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_extract_features(data):\n",
    "  try:\n",
    "    file_name = str(data.file)\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "  except FileNotFoundError:\n",
    "    file_name = str(data.file)\n",
    "    X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "  # print(file_name)\n",
    "  mfccs = np.mean(librosa.feature.mfcc(y=X,sr=sample_rate,n_mfcc=40).T,axis=0)\n",
    "  stft = np.abs(librosa.stft(X))\n",
    "  chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "  mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "  contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "  tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "  label = data.label\n",
    "  return mfccs, chroma, mel, contrast, tonnetz, label\n",
    "\n",
    "\n",
    "def instant_predict(file):\n",
    "  obj = pd.DataFrame({\"file\":file,\"label\":1},index=[0])\n",
    "  features_labels = obj.apply(single_extract_features,axis=1)\n",
    "  print(features_labels)\n",
    "  features=[]\n",
    "  for i in range(0, len(features_labels)):\n",
    "      features.append(np.concatenate((features_labels[i][0], features_labels[i][1], \n",
    "                  features_labels[i][2], features_labels[i][3],\n",
    "                  features_labels[i][4]), axis=0))\n",
    "  X = np.array(features)\n",
    "  #new_model = tf.keras.models.load_model('drive/MyDrive/Voice Detection/Saved Models/catdogmodel1')\n",
    "  return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x=instant_predict('drive/MyDrive/ProjectMGN/CatandDog/cats_dogs/test/cats/cat_30.wav')\n",
    "preds=np.argmax(predict_x,axis=1)\n",
    "preds = lb.inverse_transform(preds)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
